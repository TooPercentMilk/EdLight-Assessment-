# **EdLight Assessment - Bradley Kerr**
## Strategy
This task, image captioning, is a very well studied and documented overlap between NLP and CV. Because of this, I decided the best method to train a model was to utilize transfer learning for the majority of the task. 
- For extracting image features, I used the VGG16 architecture. Although this is a detabably outdated model, it demonstrates consistent and reliable performance, and there is plenty of documentation and tutorials on it. This model is directly accessible through the keras applications kit.
- For extracting caption features, I used the pretrained GloVe embeddings. I decided to use pretrained embeddings over learning task-specific embeddings for a few reasons. First, there is a lot of literature demonstrating that pretrained embeddings on a massive corpus often outperforms learned embeddings. Second, the guide on image captioning that I was reviewing used the flickr8k dataset, which is twice as large as this dataset. Given how much smaller our dataset is, I was skeptical that I'd have enough data to learn useful embeddings. If the captions are not strong though, I may rework the architecture to use the keras embeddings layer. I used the built-in keras LSTM model for the text processing, as LSTM's seem to be the best current method of addressing the vanishing gradient and exploding gradient problems.

## Data Augmentation
- The first obvious challenge to me was the varying image size. Most of the work I've done in the past has been with fixed input dimensions. The three main options I'm aware of (barring using a different model altogether) are cropping, resizing, or padding. I determined that all methods have downsides, and that the best approach was to use the resize_with_pad method. Just cropping wouldn't work because some of the images are very thin rectangles while others are square. Given that much of the image is text-based, and the captions seemingly rely on the dimensions of the shaped sometimes, I figure simply resizing would stretch the aspect ratio's too much. Resizing while padding the extra space seemed like the best choice to me.
- I considered greyscaling the images as well, but the VGG16 model only accepts 3-channel input, so I wouldn't gain much from doing so.