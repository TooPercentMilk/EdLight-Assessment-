{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "\n",
    "\n",
    "import gensim.downloader\n",
    "embed = gensim.downloader.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "base_directory = path + '/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method1(path, img_name):\n",
    "    # load the image from file\n",
    "    image = load_img(path, target_size=(224, 224))\n",
    "    # convert image pixels to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # preprocess image for vgg\n",
    "    image = preprocess_input(image)\n",
    "    # extract features\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    # get image ID\n",
    "    image_id = img_name.split('.')[0]\n",
    "\n",
    "    # plt.imshow(image[0, ..., 0])\n",
    "    # plt.axis('off')  # Turn off the axis\n",
    "    # plt.title(image_id)\n",
    "    # plt.show()  \n",
    "    # store feature\n",
    "    return image_id, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method2(path, img_name):\n",
    "    target_height = 224\n",
    "    target_width = 224\n",
    "    # Load and preprocess image\n",
    "    image = tf.io.read_file(path) \n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # Calculate the aspect ratio of the original image\n",
    "    original_height, original_width, _ = tf.unstack(tf.shape(image))\n",
    "    aspect_ratio = tf.cast(original_width, tf.float32) / tf.cast(original_height, tf.float32)\n",
    "\n",
    "    # Calculate the new dimensions while preserving the aspect ratio\n",
    "    if aspect_ratio > 1.0:\n",
    "        new_width = target_width\n",
    "        new_height = tf.cast(target_width / aspect_ratio, tf.int32)\n",
    "    else:\n",
    "        new_height = target_height\n",
    "        new_width = tf.cast(target_height * aspect_ratio, tf.int32)\n",
    "\n",
    "    # Resize and pad the image to the target size\n",
    "    resized_image = tf.image.resize_with_pad(image, target_height, target_width, method='bilinear')\n",
    "    resized_image = tf.image.convert_image_dtype(resized_image, tf.uint8)\n",
    "    resized_image = tf.expand_dims(resized_image, 0)\n",
    "\n",
    "    image_id = img_name.split('.')[0]\n",
    "\n",
    "    # plt.imshow(resized_image[0, ..., 0])\n",
    "    # plt.axis('off')\n",
    "    # plt.title(image_id)\n",
    "    # plt.show()  \n",
    "\n",
    "    feature = model.predict(resized_image, verbose=0)\n",
    "    return image_id, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "img_features = {}\n",
    "working_directory = base_directory + '/images'\n",
    "\n",
    "target_height = 224\n",
    "target_width = 224\n",
    "count = 0\n",
    "\n",
    "for img_name in os.listdir(working_directory):\n",
    "    if img_name.endswith('.jpg'):\n",
    "        path = working_directory + '/' + img_name\n",
    "\n",
    "        imid, fe = method2(path, img_name)\n",
    "        # imid, fe = method2(path, img_name)\n",
    "        img_features[imid] = fe\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the features because processing the data takes a while without a GPU\n",
    "pickle.dump(img_features, open(os.path.join(base_directory, 'features.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_directory, 'features.pkl'), 'rb') as f:\n",
    "    img_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = base_directory + '/descriptions.csv'\n",
    "captions = pd.read_csv(filename)\n",
    "captions['file'] = captions['file'].str[:-4]\n",
    "captions = captions[captions['file'] != 'a6a35734-ee74-42bd-a13a-dfa2b683fcda'] # outlier in length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student filled in two given sets of double number lines. In the first double number line, the student completed the top number line with \"12\\frac{1}{2}, 25, 37\\frac{1}{2} , 50, 62\\frac{1}{2} , 75, 87\\frac{1}{2} , 100, 112\\frac{1}{2} \". Note that 100 was pre-filled in the diagram. The student completed the bottom line with \"2, 3, 4, 5, 6, 7, 8, 9\". In the second double number line, the student completed the top number line with \"40, 60, 80\". The student completed the bottom number line with \"1, 2, 3\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process lines\n",
    "# captions['tokens'] = captions['description'].apply(lambda description: [word.lower() for word in word_tokenize(description)])\n",
    "\n",
    "# Create a dictionary to map labels to tokenized captions\n",
    "mappings = {}\n",
    "\n",
    "for index, row in captions.iterrows():\n",
    "    label = row['file']\n",
    "    tokens = row['description']\n",
    "    mappings[label] = tokens\n",
    "print(mappings['2d33d6a3-d2eb-496d-9ac6-832911e178f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>startseq one triangle that is identical to the...</td>\n",
       "      <td>48d27a28-851f-4fcb-82b1-b252ea5d8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>startseq one triangle drawn above the original...</td>\n",
       "      <td>420ec849-d0da-4f45-aed0-645bfa3b1d62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>startseq x written next to the original triang...</td>\n",
       "      <td>c5cc8cbc-7844-405b-a204-6aca67ef4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>startseq student drew and shaded an identical ...</td>\n",
       "      <td>abc6bf50-9b06-4c09-9e7c-90a1403ff860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>startseq a shaded triangle drawn above the ori...</td>\n",
       "      <td>231b00f3-c151-48a0-a19c-d17882ba7baf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>startseq the student filled in in the top numb...</td>\n",
       "      <td>1e49326b-9fe8-4c5a-b7e8-fa1eea1e9a0c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startseq the student labeled the bottom number...</td>\n",
       "      <td>332ea863-c4fa-4905-96bb-32fc71aa5ffe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>startseq the student filled in two given sets ...</td>\n",
       "      <td>8d32fce4-90ee-4678-910f-5fb0f60d4dce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>startseq the student filled in two given sets ...</td>\n",
       "      <td>9ca12d51-d5e0-41ee-9a9b-fd74a95f8982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>startseq the student filled in two given sets ...</td>\n",
       "      <td>2d33d6a3-d2eb-496d-9ac6-832911e178f1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  startseq one triangle that is identical to the...   \n",
       "1  startseq one triangle drawn above the original...   \n",
       "2  startseq x written next to the original triang...   \n",
       "3  startseq student drew and shaded an identical ...   \n",
       "4  startseq a shaded triangle drawn above the ori...   \n",
       "5  startseq the student filled in in the top numb...   \n",
       "6  startseq the student labeled the bottom number...   \n",
       "7  startseq the student filled in two given sets ...   \n",
       "8  startseq the student filled in two given sets ...   \n",
       "9  startseq the student filled in two given sets ...   \n",
       "\n",
       "                                   file  \n",
       "0  48d27a28-851f-4fcb-82b1-b252ea5d8295  \n",
       "1  420ec849-d0da-4f45-aed0-645bfa3b1d62  \n",
       "2  c5cc8cbc-7844-405b-a204-6aca67ef4384  \n",
       "3  abc6bf50-9b06-4c09-9e7c-90a1403ff860  \n",
       "4  231b00f3-c151-48a0-a19c-d17882ba7baf  \n",
       "5  1e49326b-9fe8-4c5a-b7e8-fa1eea1e9a0c  \n",
       "6  332ea863-c4fa-4905-96bb-32fc71aa5ffe  \n",
       "7  8d32fce4-90ee-4678-910f-5fb0f60d4dce  \n",
       "8  9ca12d51-d5e0-41ee-9a9b-fd74a95f8982  \n",
       "9  2d33d6a3-d2eb-496d-9ac6-832911e178f1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_caption(caption):\n",
    "    # Convert to lowercase\n",
    "    caption = caption.lower()\n",
    "    # Remove special characters and punctuation using regular expressions\n",
    "    caption = re.sub(r'[^a-zA-Z\\s]', '', caption)\n",
    "    caption = ' '.join(caption.split())\n",
    "    caption = 'startseq ' + caption + ' endseq'\n",
    "    return caption\n",
    "\n",
    "captions['description'] = captions['description'].apply(clean_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer(oov_token='UNK')\n",
    "tokenizer.fit_on_texts(captions['description'])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1690\n",
      "Max lenght:  30\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size: \", vocab_size)\n",
    "max_length = max(len(caption.split()) for caption in captions['description'])\n",
    "max_length = 30\n",
    "print(\"Max lenght: \", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train-test split\n",
    "image_ids = list(mappings.keys())\n",
    "split = int(len(image_ids) * 0.9)\n",
    "train = image_ids[:split]\n",
    "test = image_ids[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_keys, mapping, features, tokenizer, batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            caption = mapping[key]\n",
    "            # encode the sequence\n",
    "            seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "            # split the sequence into X, y pairs\n",
    "            for i in range(1, len(seq)):\n",
    "                # split into input and output pairs\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                # pad input sequence\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                # encode output sequence\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                \n",
    "                # store the sequences\n",
    "                X1.append(features[key][0])\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "            if n == batch_size:\n",
    "                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                yield [X1, X2], y\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1690, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embed.vectors.shape[1]))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embed:\n",
    "        embedding_matrix[i] = embed[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 16:09:12.024722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-28 16:09:12.031700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-28 16:09:12.164023: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 30, 100)      169000      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 30, 100)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 256)          365568      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1690)         434330      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,083,522\n",
      "Trainable params: 1,914,522\n",
      "Non-trainable params: 169,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "inputs1 = Input(shape=(4096,))\n",
    "fe1 = Dropout(0.4)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "# Use GloVe embeddings for the embedding layer\n",
    "se1 = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], input_length=max_length, trainable=False)(inputs2)\n",
    "se2 = Dropout(0.4)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# plot the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "    steps = len(train) // batch_size\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # create data generator\n",
    "        generator = data_generator(train, mappings, img_features, tokenizer, batch_size)\n",
    "        # fit for one epoch\n",
    "        model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "        print(\"Epoch 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 19:34:33.511034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 341s 3s/step - loss: 4.5817\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 19:40:14.597683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 355s 3s/step - loss: 4.1900\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 19:46:09.743047: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 360s 3s/step - loss: 3.8615\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 19:52:09.552994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 352s 3s/step - loss: 3.5657\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 19:58:02.159261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 347s 3s/step - loss: 3.2951\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 20:03:49.195186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 349s 3s/step - loss: 3.0690\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 20:09:38.604624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 386s 3s/step - loss: 2.9265\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 20:16:04.954680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 358s 3s/step - loss: 2.7534\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 20:22:03.698514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 361s 3s/step - loss: 2.6235\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 20:28:04.882257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 370s 3s/step - loss: 2.4968\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(base_directory + '/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to generate captions\n",
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        # encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad the sequence\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        # get index with high probability\n",
    "        oov_ind = np.argmax(yhat)\n",
    "        yhat[0, oov_ind] = 0\n",
    "        yhat = np.argmax(yhat)\n",
    "        # convert index to word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        # stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        # append word as input for generating next word\n",
    "        in_text += \" \" + word\n",
    "        # stop if we reach end tag\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "      \n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 09:10:45.018709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-28 09:10:45.021609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-28 09:10:45.023548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# if I want to load a previous model \n",
    "model = load_model(base_directory + '/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-28 09:12:14.025728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-28 09:12:14.027724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-28 09:12:14.029242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brad/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/brad/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/brad/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.000068\n",
      "BLEU-2: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "# validate with test data\n",
    "actual, predicted = list(), list()\n",
    "\n",
    "count = 0\n",
    "for key in test:\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    # get actual caption\n",
    "    captions = mappings[key]\n",
    "    # predict the caption for image\n",
    "    y_pred = predict_caption(model, img_features[key], tokenizer, max_length) \n",
    "    # split into words\n",
    "    actual_captions = [caption.split() for caption in captions]\n",
    "    y_pred = y_pred.split()\n",
    "    # append to the list\n",
    "    actual.append(actual_captions)\n",
    "    predicted.append(y_pred)\n",
    "    \n",
    "# calcuate BLEU score\n",
    "print(\"BLEU-1: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "print(\"BLEU-2: %f\" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def generate_caption(image_name):\n",
    "    # load the image\n",
    "    image_id = image_name.split('.')[0]\n",
    "    img_path = os.path.join(base_directory, \"images\", image_name)\n",
    "    image = Image.open(img_path)\n",
    "    caption = mappings[image_id]\n",
    "    print('---------------------Actual---------------------')\n",
    "    print(caption)\n",
    "    # predict the caption\n",
    "    y_pred = predict_caption(model, img_features[image_id], tokenizer, max_length)\n",
    "    print('--------------------Predicted--------------------')\n",
    "    print(y_pred)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Actual---------------------\n",
      "Polygon ABCD with a scaled copy polygon PQRS\n",
      "Polygon ABCD has side length AB labeled 1 and side length AD labeled 2.\n",
      "Polygon PQRS has side length PQ labeled 1.5 and side length PS labeled 3.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/brad/Desktop/EdLight Assessment/build_model.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m generate_caption(\u001b[39m'\u001b[39;49m\u001b[39m927edacd-9f8f-46fe-bcbf-1830ae7868c5.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/brad/Desktop/EdLight Assessment/build_model.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(caption)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# predict the caption\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m predict_caption(model, img_features[image_id], tokenizer, max_length)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m--------------------Predicted--------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(y_pred)\n",
      "\u001b[1;32m/Users/brad/Desktop/EdLight Assessment/build_model.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# get index with high probability\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m oov_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(yhat)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m yhat[\u001b[39m0\u001b[39m, oov_ind] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m yhat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(yhat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# convert index to word\u001b[39;00m\n",
      "\u001b[1;32m/Users/brad/Desktop/EdLight Assessment/build_model.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# get index with high probability\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m oov_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(yhat)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m yhat[\u001b[39m0\u001b[39m, oov_ind] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m yhat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(yhat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brad/Desktop/EdLight%20Assessment/build_model.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# convert index to word\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_caption('927edacd-9f8f-46fe-bcbf-1830ae7868c5.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UNK': 1, 'the': 2, 'startseq': 3, 'endseq': 4, 'is': 5, 'and': 6, 'with': 7, 'of': 8, 'a': 9, 'labeled': 10, 'to': 11, 'line': 12, 'in': 13, 'written': 14, 'rectangle': 15, 'row': 16, 'drawn': 17, 'number': 18, 'it': 19, 'right': 20, 'from': 21, 'above': 22, 'on': 23, 'triangle': 24, 'two': 25, 'student': 26, 'first': 27, 'left': 28, 'are': 29, 'each': 30, 'diagram': 31, 'into': 32, 'side': 33, 'table': 34, 'second': 35, 'has': 36, 'out': 37, 'x': 38, 'below': 39, 'arrow': 40, 'crossed': 41, 'top': 42, 'height': 43, 'tape': 44, 'drew': 45, 'one': 46, 'circled': 47, 'at': 48, 'figure': 49, 'three': 50, 'for': 51, 'b': 52, 'an': 53, 'width': 54, 'inside': 55, 'by': 56, 'as': 57, 'there': 58, 'c': 59, 'box': 60, 'horizontal': 61, 'rows': 62, 'shaded': 63, 'bottom': 64, 'units': 65, 'vertical': 66, 'shape': 67, 'column': 68, 'through': 69, 'columns': 70, 'length': 71, 'that': 72, 'd': 73, 'lines': 74, 'parts': 75, 'sections': 76, 'frac': 77, 'marks': 78, 'third': 79, 'section': 80, 'between': 81, 'divided': 82, 'next': 83, 'unit': 84, 'cm': 85, 'base': 86, 'times': 87, 'tick': 88, 'diagonal': 89, 'boxes': 90, 'parallelogram': 91, 'equal': 92, 'split': 93, 'polygon': 94, 'm': 95, 'area': 96, 'model': 97, 'marked': 98, 'points': 99, 'long': 100, 'outer': 101, 'ratio': 102, 'triangles': 103, 'vertex': 104, 'squares': 105, 'wrote': 106, 'e': 107, 'div': 108, 'bar': 109, 's': 110, 'under': 111, 'underlined': 112, 'inner': 113, 'numbers': 114, 'pieces': 115, 'point': 116, 'given': 117, 'then': 118, 'square': 119, 'segment': 120, 'increments': 121, 'sides': 122, 'h': 123, 'y': 124, 'pointing': 125, 'four': 126, 'connecting': 127, 'prism': 128, 'underneath': 129, 'total': 130, 'cdot': 131, 'double': 132, 'portion': 133, 'part': 134, 'draws': 135, 'angle': 136, 'not': 137, 'plane': 138, 'coordinate': 139, 'down': 140, 'small': 141, 'five': 142, 'other': 143, 'grouped': 144, 'rectangular': 145, 'make': 146, 'this': 147, 'create': 148, 'arrows': 149, 'labelled': 150, 'using': 151, 'which': 152, 'bags': 153, 'around': 154, 'ft': 155, 'labels': 156, 'ears': 157, 'same': 158, 'all': 159, 'middle': 160, 'tall': 161, 'dollars': 162, 'another': 163, 'made': 164, 'paws': 165, 'correctly': 166, 'intervals': 167, 'they': 168, 'circles': 169, 'distance': 170, 'equation': 171, 'hexagon': 172, 'rice': 173, 'illegible': 174, 'word': 175, 'both': 176, 'created': 177, 'f': 178, 'rectangles': 179, 'lengths': 180, 'l': 181, 'over': 182, 'cost': 183, 'cups': 184, 'original': 185, 'up': 186, 'symbol': 187, 'plotted': 188, 'last': 189, 'blank': 190, 'u': 191, 'along': 192, 'size': 193, 'st': 194, 'question': 195, 'leftright': 196, 'segments': 197, 'threefourths': 198, 'angles': 199, 'them': 200, 'sided': 201, 'diagrams': 202, 'final': 203, 'space': 204, 'letter': 205, 'nd': 206, 'counts': 207, 'circle': 208, 'half': 209, 'front': 210, 'rightmost': 211, 'pairs': 212, 'perpendicular': 213, 'taste': 214, 'smaller': 215, 'vertices': 216, 'division': 217, 'medium': 218, 'bases': 219, 'fourth': 220, 'decomposed': 221, 'heights': 222, 'starting': 223, 'flour': 224, 'actual': 225, 'counted': 226, 'vanilla': 227, 'contains': 228, 'edge': 229, 'pyramid': 230, 'value': 231, 'isosceles': 232, 'gcf': 233, 'values': 234, 'new': 235, 'hypotenuse': 236, 'altitude': 237, 'or': 238, 'end': 239, 'would': 240, 'recipe': 241, 'juice': 242, 'cutout': 243, 'penultimate': 244, 'have': 245, 'slope': 246, 'heading': 247, 'starts': 248, 'block': 249, 'touch': 250, 'group': 251, 'upper': 252, 'p': 253, 'mixtures': 254, 'connects': 255, 'groups': 256, 'cube': 257, 'decimal': 258, 'partitioned': 259, 'axis': 260, 'show': 261, 'answer': 262, 'problem': 263, 'followed': 264, 'whole': 265, 'lower': 266, 'form': 267, 'rearranged': 268, 'its': 269, 'these': 270, 'curved': 271, 'large': 272, 'different': 273, 'measurements': 274, 'represent': 275, 'readable': 276, 'abcd': 277, 'inches': 278, 'arc': 279, 'plots': 280, 'sketch': 281, 'dot': 282, 'rd': 283, 'v': 284, 'cut': 285, 'spaced': 286, 't': 287, 'step': 288, 'six': 289, 'g': 290, 'pqrs': 291, 'markings': 292, 'moved': 293, 'because': 294, 'red': 295, 'orange': 296, 'tail': 297, 'choice': 298, 'unlabeled': 299, 'ending': 300, 'will': 301, 'onefourth': 302, 'grid': 303, 'letters': 304, 'correct': 305, 'colored': 306, 'endpoint': 307, 'sized': 308, 'containing': 309, 'o': 310, 'minutes': 311, 'identical': 312, 'i': 313, 'center': 314, 'meters': 315, 'also': 316, 'represents': 317, 'cat': 318, 'th': 319, 'pineapple': 320, 'no': 321, 'equally': 322, 'vertically': 323, 'dots': 324, 'time': 325, 'midpoint': 326, 'teaspoons': 327, 'connected': 328, 'corner': 329, 'scaled': 330, 'where': 331, 'figures': 332, 'extended': 333, 'rate': 334, 'quality': 335, 'extends': 336, 'boxed': 337, 'sa': 338, 'fourths': 339, 'added': 340, 'distances': 341, 'was': 342, 'moving': 343, 'tails': 344, 'degrees': 345, 'increment': 346, 'displays': 347, 'wide': 348, 'across': 349, 'shapes': 350, 'copy': 351, 'says': 352, 'decompose': 353, 'tables': 354, 'cubic': 355, 'following': 356, 'product': 357, 'determine': 358, 'draw': 359, 'approximately': 360, 'annotated': 361, 'representing': 362, 'beginning': 363, 'but': 364, 'entire': 365, 'ounces': 366, 'place': 367, 'those': 368, 'compared': 369, 'determining': 370, 'pair': 371, 'scale': 372, 'showing': 373, 'off': 374, 'face': 375, 'data': 376, 'kilometers': 377, 'twofourths': 378, 'hexagons': 379, 'ms': 380, 'horizontally': 381, 'together': 382, 'mark': 383, 'how': 384, 'price': 385, 'midway': 386, 'gray': 387, 'typed': 388, 'r': 389, 'you': 390, 'seeds': 391, 'scalene': 392, 'rates': 393, 'filled': 394, 'parallel': 395, 'shows': 396, 'counting': 397, 'spaces': 398, 'per': 399, 'least': 400, 'onehalf': 401, 'blue': 402, 'label': 403, 'be': 404, 'more': 405, 'quadrilateral': 406, 'set': 407, 'bracket': 408, 'stacked': 409, 'start': 410, 'grapes': 411, 'syrup': 412, 'gal': 413, 'indicate': 414, 'composed': 415, 'larger': 416, 'he': 417, 'equals': 418, 'about': 419, 'volume': 420, 'text': 421, 'ratios': 422, 'dough': 423, 'trapezoid': 424, 'pounds': 425, 'so': 426, 'highlighted': 427, 'ad': 428, 'feet': 429, 'equivalent': 430, 'prisms': 431, 'park': 432, 'completed': 433, 'graph': 434, 'yaxis': 435, 'described': 436, 'attached': 437, 'ps': 438, 'expression': 439, 'sauce': 440, 'room': 441, 'tablespoons': 442, 'piece': 443, 'aligning': 444, 'drawing': 445, 'change': 446, 'items': 447, 'places': 448, 'sign': 449, 'identified': 450, 'net': 451, 'yellow': 452, 'k': 453, 'beneath': 454, 'greatest': 455, 'region': 456, 'signal': 457, 'enclosed': 458, 'writes': 459, 'lin': 460, 'used': 461, 'calculated': 462, 'standard': 463, 'algorithm': 464, 'additional': 465, 'placed': 466, 'hanger': 467, 'after': 468, 'hours': 469, 'leftdivright': 470, 'q': 471, 'equilateral': 472, 'ab': 473, 'fivesided': 474, 'cats': 475, 'kitchen': 476, 'dividend': 477, 'comparing': 478, 'ordered': 479, 'maple': 480, 'twothirds': 481, 'finally': 482, 'got': 483, 'write': 484, 'stem': 485, 'decomposes': 486, 'titled': 487, 'xs': 488, 'bc': 489, 'replaced': 490, 'inch': 491, 'finish': 492, 'playroom': 493, 'dining': 494, 'cd': 495, 'writing': 496, 'sharing': 497, 'beside': 498, 'liter': 499, 'traced': 500, 'pq': 501, 'coming': 502, 'xaxis': 503, 'now': 504, 'did': 505, 'without': 506, 'multiplication': 507, 'extending': 508, 'less': 509, 'complete': 510, 'diameter': 511, 'radius': 512, 'dashed': 513, 'plus': 514, 'perimeter': 515, 'if': 516, 'respectively': 517, 'rs': 518, 'frequency': 519, 'liters': 520, 'gallons': 521, 'parallelograms': 522, 'able': 523, 'triangular': 524, 'having': 525, 'meet': 526, 'quadrant': 527, 'count': 528, 'going': 529, 'downward': 530, 'lins': 531, 'dimensions': 532, 'separated': 533, 'title': 534, 'words': 535, 'explain': 536, 'outside': 537, 'water': 538, 'broke': 539, 'km': 540, 'zero': 541, 'guests': 542, 'percent': 543, 'cell': 544, 'baseten': 545, 'centimeters': 546, 'accurately': 547, 'situation': 548, 'work': 549, 'elena': 550, 'within': 551, 'solved': 552, 'multiplied': 553, 'much': 554, 'consisting': 555, 'lined': 556, 'broken': 557, 'corresponds': 558, 'kg': 559, 'factor': 560, 'tsp': 561, 'purple': 562, 'nine': 563, 'named': 564, 'goes': 565, 'shades': 566, 'shown': 567, 'quadrilaterals': 568, 'elenas': 569, 'plot': 570, 'cup': 571, 'back': 572, 'bag': 573, 'quotient': 574, 'add': 575, 'apples': 576, 'incorrect': 577, 'timesfrac': 578, 'diamond': 579, 'measures': 580, 'oj': 581, 'paper': 582, 'can': 583, 'origin': 584, 'amount': 585, 'opposite': 586, 'chart': 587, 'surface': 588, 'incorrectly': 589, 'run': 590, 'subtracted': 591, 'creating': 592, 'far': 593, 'corresponding': 594, 'leftxright': 595, 'phrase': 596, 'dr': 597, 'making': 598, 'histogram': 599, 'her': 600, 'called': 601, 'being': 602, 'valued': 603, 'diagonally': 604, 'towards': 605, 'compose': 606, 'xx': 607, 'objects': 608, 'crane': 609, 'xyz': 610, 'aligned': 611, 'begins': 612, 'centimeter': 613, 'shading': 614, 'their': 615, 'congruent': 616, 'ear': 617, 'students': 618, 'handwriting': 619, 'than': 620, 'un': 621, 'tow': 622, 'rise': 623, 'median': 624, 'well': 625, 'subtraction': 626, 'onto': 627, 'directly': 628, 'star': 629, 'polygons': 630, 'what': 631, 'fraction': 632, 'pr': 633, 'pyramids': 634, 'goal': 635, 'pencil': 636, 'key': 637, 'tic': 638, 'weight': 639, 'separating': 640, 'clockwise': 641, 'apply': 642, 'lefttimesright': 643, 'ins': 644, 'makes': 645, 'bumps': 646, 'bcd': 647, 'squared': 648, 'pentagon': 649, 'seedssyrup': 650, 'mixture': 651, 'dt': 652, 'parentheses': 653, 'sets': 654, 'appropriate': 655, 'solid': 656, 'just': 657, 'connect': 658, 'headings': 659, 'put': 660, 'way': 661, 'z': 662, 'unequally': 663, 'tchart': 664, 'percentage': 665, 'single': 666, 'sketched': 667, 'pqrst': 668, 'halfway': 669, 'n': 670, 'visible': 671, 'adds': 672, 'divisor': 673, 'here': 674, 'outlined': 675, 'get': 676, 'use': 677, 'account': 678, 'sectioned': 679, 'were': 680, 'every': 681, 'speed': 682, 'timesdiv': 683, 'happy': 684, 'his': 685, 'j': 686, 'obox': 687, 'measurement': 688, 'qr': 689, 'tangram': 690, 'regular': 691, 'batchfrac': 692, 'indicated': 693, 'centerpiece': 694, 'deg': 695, 'straight': 696, 'money': 697, 'coordinates': 698, 'indicating': 699, 'bring': 700, 'denominator': 701, 'includes': 702, 'noahs': 703, 'batch': 704, 'leg': 705, 'measuring': 706, 'find': 707, 'cylinder': 708, 'leftmost': 709, 'several': 710, 'cone': 711, 'degree': 712, 'lattice': 713, 'sq': 714, 'fifth': 715, 'curves': 716, 'cdotcdot': 717, 'abcde': 718, 'pt': 719, 'taller': 720, 'turned': 721, 'yard': 722, 'divide': 723, 'newly': 724, 'some': 725, 'annotation': 726, 'big': 727, 'description': 728, 'min': 729, 'andre': 730, 'divfrac': 731, 'solution': 732, 'digits': 733, 'fraccdotfrac': 734, 'uneven': 735, 'fractimesfracfrac': 736, 'balance': 737, 'days': 738, 'deposit': 739, 'day': 740, 'countermarks': 741, 'seconds': 742, 'color': 743, 'found': 744, 'hit': 745, 'fractions': 746, 'thinking': 747, 'hight': 748, 'pj': 749, 'cranes': 750, 'isx': 751, 'however': 752, 'annotates': 753, 'does': 754, 'picture': 755, 'describe': 756, 'open': 757, 'many': 758, 'turn': 759, 'sf': 760, 'do': 761, 'answers': 762, 'numerator': 763, 'decomposing': 764, 'cubes': 765, 'numerical': 766, 'marking': 767, 'halves': 768, 'very': 769, 'boxpart': 770, 'nothing': 771, 'could': 772, 'partsboxes': 773, 'percentages': 774, 'empty': 775, 'lining': 776, 'only': 777, 'ae': 778, 'dc': 779, 'ts': 780, 'sr': 781, 'dotted': 782, 'minus': 783, 'smiley': 784, 'thirds': 785, 'foot': 786, 'break': 787, 'xfrac': 788, 'order': 789, 'including': 790, 'yourself': 791, 'divr': 792, 'abc': 793, 'buy': 794, 'formed': 795, 'had': 796, 'labeling': 797, 'inline': 798, 'counter': 799, 'fraccdotfracfrac': 800, 'w': 801, 'hundredths': 802, 'ones': 803, 'calculation': 804, 'temperature': 805, 'sum': 806, 'multiply': 807, 'noah': 808, 'transcribes': 809, 'sixfourths': 810, 'represented': 811, 'statement': 812, 'vinilla': 813, 'yards': 814, 'provided': 815, 'dogs': 816, 'mice': 817, 'redrew': 818, 'cdotfrac': 819, 'miscalculated': 820, 'ac': 821, 'namely': 822, 'flourcups': 823, 'boundary': 824, 'partthere': 825, 'removed': 826, 'spoons': 827, 'seed': 828, 'showed': 829, 'header': 830, 'entries': 831, 'hexagonal': 832, 'pentagonal': 833, 'cdotx': 834, 'been': 835, 'explanation': 836, 'transformed': 837, 'yintercept': 838, 'etc': 839, 'until': 840, 'ends': 841, 'read': 842, 'translated': 843, 'sc': 844, 'separate': 845, 'pink': 846, 'beyond': 847, 'again': 848, 'like': 849, 'rearrange': 850, 'tenths': 851, 'addition': 852, 'throughout': 853, 'overlapping': 854, 'pi': 855, 'whisker': 856, 'boxesparts': 857, 'full': 858, 'consists': 859, 'passes': 860, 'volumes': 861, 'reasoning': 862, 'ba': 863, 'ed': 864, 'rq': 865, 'qp': 866, 'hurdles': 867, 'cub': 868, 'increased': 869, 'remaining': 870, 'list': 871, 'numbered': 872, 'meter': 873, 'acute': 874, 'underline': 875, 'once': 876, 'host': 877, 'divleftright': 878, 'sqrt': 879, 'know': 880, 'we': 881, 'expressions': 882, 'counters': 883, 'bigger': 884, 'variable': 885, 'mins': 886, 'identifies': 887, 'creates': 888, 'school': 889, 'pound': 890, 'divtimes': 891, 'fracx': 892, 'unshaded': 893, 'gap': 894, 'thousandths': 895, 'fracdivfrac': 896, 'edges': 897, 'oriented': 898, 'pemdas': 899, 'jada': 900, 'jumps': 901, 'continue': 902, 'charged': 903, 'before': 904, 'rewrote': 905, 'rewrites': 906, 'needed': 907, 'didnt': 908, 'calculates': 909, 'variability': 910, 'canada': 911, 'onethird': 912, 'outline': 913, 'displaying': 914, 'gallon': 915, 'unequal': 916, 'composite': 917, 'dilated': 918, 'hard': 919, 'flower': 920, 'walks': 921, 'map': 922, 'performed': 923, 'notation': 924, 'why': 925, 'widths': 926, 'based': 927, 'neither': 928, 'topmost': 929, 'identify': 930, 'reflected': 931, 'vanillateaspoons': 932, 'rearranges': 933, 'bolded': 934, 'partthe': 935, 'move': 936, 'trapezoids': 937, 'facing': 938, 'boc': 939, 'aob': 940, 'reflection': 941, 'pqr': 942, 'repeating': 943, 'constant': 944, 'diffrent': 945, 'prisan': 946, 'note': 947, 'prefilled': 948, 'error': 949, 'upward': 950, 'divides': 951, 'formula': 952, 'attempt': 953, 'attempted': 954, 'underlines': 955, 'linear': 956, 'explained': 957, 'clear': 958, 'drawsa': 959, 'identifying': 960, 'check': 961, 'drawings': 962, 'rotated': 963, 'labled': 964, 'fractional': 965, 'combine': 966, 'continuous': 967, 'near': 968, 'singular': 969, 'placing': 970, 'result': 971, 'pages': 972, 'inclosed': 973, 'normal': 974, 'bottle': 975, 'high': 976, 'splitting': 977, 'trend': 978, 'negative': 979, 'consecutive': 980, 'longer': 981, 'inputoutput': 982, 'cu': 983, 'tallies': 984, 'kilo': 985, 'miles': 986, 'margin': 987, 'sphere': 988, 'approximation': 989, 'farther': 990, 'models': 991, 'random': 992, 'location': 993, 'cross': 994, 'weigh': 995, 'apple': 996, 'she': 997, 'deconstructed': 998, 'rhombus': 999, 'slightly': 1000, 'powers': 1001, 'exponents': 1002, 'expanded': 1003, 'little': 1004, 'instead': 1005, 'takes': 1006, 'rest': 1007, 'valuation': 1008, 'cells': 1009, 'qualitywritten': 1010, 'scratch': 1011, 'cuts': 1012, 'anf': 1013, 'amd': 1014, 'py': 1015, 'sentence': 1016, 'fractimesfrac': 1017, 'fracdivfracfractimesfracfrac': 1018, 'outlier': 1019, 'timestimes': 1020, 'ca': 1021, 'smallest': 1022, 'dash': 1023, 'grouping': 1024, 'rewritten': 1025, 'exponent': 1026, 'stay': 1027, 'method': 1028, 'unitsquare': 1029, 'dividing': 1030, 'xcdot': 1031, 'fee': 1032, 'fracdiv': 1033, 'temp': 1034, 'erased': 1035, 'applies': 1036, 'gridlines': 1037, 'transposes': 1038, 'applied': 1039, 'resulting': 1040, 'shade': 1041, 'ans': 1042, 'multiplying': 1043, 'aillegible': 1044, 'say': 1045, 'iqr': 1046, 'evenly': 1047, 'eighth': 1048, 'sixth': 1049, 'leftcdotright': 1050, 'ranging': 1051, 'discrete': 1052, 'batches': 1053, 'repeated': 1054, 'fracfrac': 1055, 'gall': 1056, 'listed': 1057, 'toward': 1058, 'leters': 1059, 'cutting': 1060, 'lightly': 1061, 'darker': 1062, 'even': 1063, 'furthest': 1064, 'graphed': 1065, 'dilating': 1066, 'difference': 1067, 'roughly': 1068, 'scored': 1069, 'omitted': 1070, 'cof': 1071, 'balanced': 1072, 'annotations': 1073, 'encloses': 1074, 'house': 1075, 'fish': 1076, 'round': 1077, 'score': 1078, 'tally': 1079, 'tank': 1080, 'missed': 1081, 'seven': 1082, 'measure': 1083, 'outlines': 1084, 'tblspns': 1085, 'animals': 1086, 'attempts': 1087, 'follow': 1088, 'symbolize': 1089, 'fit': 1090, 'amounts': 1091, 'mole': 1092, 'look': 1093, 'any': 1094, 'converts': 1095, 'selected': 1096, 'copies': 1097, 'colores': 1098, 'meets': 1099, 'return': 1100, 'byfrac': 1101, 'leftyfracright': 1102, 'constructed': 1103, 'cause': 1104, 'parrallelogram': 1105, 'addeddrawn': 1106, 'counterclockwise': 1107, 'brown': 1108, 'aoc': 1109, 'partsthe': 1110, 'substituted': 1111, 'sp': 1112, 'interior': 1113, 'dab': 1114, 'spq': 1115, 'tase': 1116, 'qt': 1117, 'checkmark': 1118, 'obtuse': 1119, 'paint': 1120, 'mi': 1121, 'xle': 1122, 'arrowarrow': 1123, 'snow': 1124, 'hearts': 1125, 'stars': 1126, 'continued': 1127, 'ontop': 1128, 'completing': 1129, 'heighttimes': 1130, 'partial': 1131, 'slopes': 1132, 'yintercepts': 1133, 'nonlattice': 1134, 'fracyx': 1135, 'fracriserunfracfrac': 1136, 'adjacent': 1137, 'equalsized': 1138, 'begin': 1139, 'pass': 1140, 'xample': 1141, 'transforming': 1142, 'am': 1143, 'denote': 1144, 'raised': 1145, 'plotting': 1146, 'graphing': 1147, 'nearly': 1148, 'stops': 1149, 'relationship': 1150, 'close': 1151, 'runs': 1152, 'cannot': 1153, 'clearly': 1154, 'fracyxfrac': 1155, 'arrowing': 1156, 'examples': 1157, 'existing': 1158, 'understanding': 1159, 'decomposition': 1160, 'theres': 1161, 'cool': 1162, 'sheet': 1163, 'ls': 1164, 'corect': 1165, 'totaling': 1166, 'drawsmodel': 1167, 'representation': 1168, 'fot': 1169, 'axes': 1170, 'tale': 1171, 'fracfracfracfrac': 1172, 'name': 1173, 'breaking': 1174, 'sentences': 1175, 'exit': 1176, 'ticket': 1177, 'cubs': 1178, 'wcdot': 1179, 'thru': 1180, 'batchs': 1181, 'lists': 1182, 'baches': 1183, 'linesnot': 1184, 'fracfracfracfracfracfracfracfracfrac': 1185, 'fracfracfrac': 1186, 'efgh': 1187, 'quals': 1188, 'rather': 1189, 'rw': 1190, 'reflects': 1191, 'spit': 1192, 'fracfracfracfracfracfracfrac': 1193, 'root': 1194, 'boxparts': 1195, 'matching': 1196, 'changes': 1197, 'spending': 1198, 'labelling': 1199, 'previous': 1200, 'female': 1201, 'humpb': 1202, 'male': 1203, 'humpback': 1204, 'contain': 1205, 'lastth': 1206, 'non': 1207, 'intersecting': 1208, 'parenthesis': 1209, 'additionally': 1210, 'ml': 1211, 'tcharts': 1212, 'cf': 1213, 'de': 1214, 'lt': 1215, 'pack': 1216, 'milk': 1217, 'cartons': 1218, 'separately': 1219, 'away': 1220, 'reaching': 1221, 'drown': 1222, 'shapemissing': 1223, 'midpoints': 1224, 'vertice': 1225, 'trianlge': 1226, 'paralellogram': 1227, 'become': 1228, 'botom': 1229, 'itself': 1230, 'qualitynot': 1231, 'begs': 1232, 'leftleftrightrightleftright': 1233, 'leftrightleftright': 1234, 'leftrightleftrightleftright': 1235, 'inchis': 1236, 'poliygon': 1237, 'irregular': 1238, 'bro': 1239, 'threethirds': 1240, 'eg': 1241, 'scales': 1242, 'divx': 1243, 'crossing': 1244, 'multiples': 1245, 'something': 1246, 'finished': 1247, 'sideand': 1248, 'scribbles': 1249, 'illegibleillegibleillegibleillegible': 1250, 'individually': 1251, 'view': 1252, 'dimensional': 1253, 'br': 1254, 'border': 1255, 'kn': 1256, 'kitchin': 1257, 'ounce': 1258, 'scratched': 1259, 'needs': 1260, 'connection': 1261, 'people': 1262, 'pen': 1263, 'kilometer': 1264, 'states': 1265, 'initial': 1266, 'person': 1267, 'kilkometers': 1268, 'eating': 1269, 'concave': 1270, 'tack': 1271, 'classifying': 1272, 'eb': 1273, 'positive': 1274, 'wrong': 1275, 'herecdot': 1276, 'equaling': 1277, 'hand': 1278, 'threw': 1279, 'crosses': 1280, 'multiple': 1281, 'borders': 1282, 'littile': 1283, 'white': 1284, 'fundraising': 1285, 'best': 1286, 'definition': 1287, 'polyhedron': 1288, 'terms': 1289, 'learned': 1290, 'lesson': 1291, 'classified': 1292, 'xpyramids': 1293, 'oprism': 1294, 'dprism': 1295, 'increasing': 1296, 'mt': 1297, 'decreasing': 1298, 'onea': 1299, 'walk': 1300, 'orginal': 1301, 'setup': 1302, 'divdiv': 1303, 'meaning': 1304, 'pizza': 1305, 'scretched': 1306, 'areas': 1307, 'follows': 1308, 'wote': 1309, 'world': 1310, 'thick': 1311, 'dollar': 1312, 'cancled': 1313, 'fracxleftfracright': 1314, 'underlining': 1315, 'behind': 1316, 'game': 1317, 'simeticle': 1318, 'major': 1319, 'peek': 1320, 'bcdot': 1321, 'hcdotfraca': 1322, 'bars': 1323, 'fraccdotfraccdot': 1324, 'ta': 1325, 'dv': 1326, 'tenth': 1327, 'grapespounds': 1328, 'leads': 1329, 'stating': 1330, 'playgroud': 1331, 'dinnar': 1332, 'tallest': 1333, 'peac': 1334, 'games': 1335, 'faces': 1336, 'symetrical': 1337, 'lline': 1338, 'te': 1339, 'oo': 1340, 'ooooooo': 1341, 'ooooo': 1342, 'false': 1343, 'mediums': 1344, 'intersect': 1345, 'distinct': 1346, 'intersection': 1347, 'similarly': 1348, 'shaped': 1349, 'fracdivfracfraccdotfracfracin': 1350, 'play': 1351, 'exp': 1352, 'leftcdotcdotcdotrightcdotleftcdotcdotcdotrightleftcdotrightcdotleftcdotrightcdotleftcdotrightcdotleftcdotrightcdotcdotcdot': 1353, 'lapeled': 1354, 'circcled': 1355, 'agree': 1356, 'cubit': 1357, 'calculate': 1358, 'annoted': 1359, 'fraccdotfracfraccdotfracfracin': 1360, 'blocks': 1361, 'fraccdotfraccdotfrac': 1362, 'arranged': 1363, 'array': 1364, 'fac': 1365, 'methods': 1366, 'rounded': 1367, 'computation': 1368, 'frachtimesleftfractimesfracfracright': 1369, 'fracin': 1370, 'fracfractimesfracfrac': 1371, 'rotate': 1372, 'later': 1373, 'fraccdot': 1374, 'hfracdivfrac': 1375, 'ticks': 1376, 'must': 1377, 'ten': 1378, 'results': 1379, 'ads': 1380, 'dekcomepos': 1381, 'phrases': 1382, 'today': 1383, 'sisters': 1384, 'transactions': 1385, 'besides': 1386, 'daily': 1387, 'your': 1388, 'needing': 1389, 'rights': 1390, 'digit': 1391, 'transcribed': 1392, 'wrties': 1393, 'position': 1394, 'running': 1395, 'children': 1396, 'example': 1397, 'labeledvalued': 1398, 'fin': 1399, 'twice': 1400, 'tablest': 1401, 'wholes': 1402, 'south': 1403, 'africa': 1404, 'oval': 1405, 'recreate': 1406, 'years': 1407, 'old': 1408, 'while': 1409, 'constraint': 1410, 'remove': 1411, 'lenth': 1412, 'ape': 1413, 'leftbright': 1414, 'dneng': 1415, 'signs': 1416, 'ninth': 1417, 'seventh': 1418, 'handwritten': 1419, 'entered': 1420, 'entry': 1421, 'lefttimes': 1422, 'cdotwritten': 1423, 'timeswritten': 1424, 'legible': 1425, 'fourfourths': 1426, 'inaccurate': 1427, 'xcdotx': 1428, 'partwhole': 1429, 'totalwhole': 1430, 'except': 1431, 'fully': 1432, 'labeld': 1433, 'portions': 1434, 'higher': 1435, 'mean': 1436, 'mad': 1437, 'australia': 1438, 'zealand': 1439, 'threefourth': 1440, 'lit': 1441, 'titles': 1442, 'bacthe': 1443, 'ine': 1444, 'handwritingx': 1445, 'mimics': 1446, 'algebra': 1447, 'tiles': 1448, 'ray': 1449, 'rotation': 1450, 'max': 1451, 'headers': 1452, 'plan': 1453, 'pts': 1454, 'geometric': 1455, 'likely': 1456, 'doodles': 1457, 'tspov': 1458, 'erase': 1459, 'land': 1460, 'soltion': 1461, 'fracfracfracfracfracfracfracfracfracfrac': 1462, 'linwalks': 1463, 'colser': 1464, 'yeards': 1465, 'biger': 1466, 'becaus': 1467, 'images': 1468, 'tanks': 1469, 'sizes': 1470, 'alana': 1471, 'friendsfeetiqr': 1472, 'friends': 1473, 'inbetween': 1474, 'pints': 1475, 'flowr': 1476, 'closerto': 1477, 'brother': 1478, 'sohe': 1479, 'kilograms': 1480, 'shot': 1481, 'yvalues': 1482, 'associated': 1483, 'ex': 1484, 'xvalue': 1485, 'lives': 1486, 'farter': 1487, 'schooll': 1488, 'denoting': 1489, 'soluton': 1490, 'regrouped': 1491, 'option': 1492, 'nonequal': 1493, 'faint': 1494, 'checkmarks': 1495, 'similar': 1496, 'ascending': 1497, 'halfmoon': 1498, 'shared': 1499, 'think': 1500, 'yield': 1501, 'cs': 1502, 'syrupmaple': 1503, 'collection': 1504, 'included': 1505, 'input': 1506, 'output': 1507, 'enlarged': 1508, 'choices': 1509, 'wrotestudent': 1510, 'wrotexannotated': 1511, 'wrotefracxfracfrac': 1512, 'fracfracor': 1513, 'ne': 1514, 'wrotethe': 1515, 'eight': 1516, 'meider': 1517, 'thare': 1518, 'moel': 1519, 'sidesthat': 1520, 'allowing': 1521, 'align': 1522, 'incomplete': 1523, 'tsps': 1524, 'dthree': 1525, 'escriptiondescribe': 1526, 'oz': 1527, 'should': 1528, 'thats': 1529, 'lenthgs': 1530, 'bagels': 1531, 'studentshowed': 1532, 'btimes': 1533, 'either': 1534, 'adding': 1535, 'surrounding': 1536, 'misshapen': 1537, 'heretimes': 1538, 'duplicate': 1539, 'unknown': 1540, 'cents': 1541, 'sectionnot': 1542, 'thicker': 1543, 'eaillegible': 1544, 'hthe': 1545, 'bottomillegible': 1546, 'portioned': 1547, 'thhe': 1548, 'workspace': 1549, 'upside': 1550, 'itthe': 1551, 'though': 1552, 'abd': 1553, 'ride': 1554, 'solve': 1555, 'traingle': 1556, 'ever': 1557, 'perimiter': 1558, 'fstudent': 1559, 'numberline': 1560, 'actuall': 1561, 'subtracts': 1562, 'started': 1563, 'began': 1564, 'cmand': 1565, 'marksbelow': 1566, 'mcm': 1567, 'mc': 1568, 'yd': 1569, 'vanillatsp': 1570, 'thes': 1571, 'tudent': 1572, 'figureneither': 1573, 'legibleillegible': 1574, 'factoring': 1575, 'threes': 1576, 'interval': 1577, 'crltc': 1578, 'crlt': 1579, 'studen': 1580, 'wich': 1581, 'parallelog': 1582, 'rotaten': 1583, 'justification': 1584, 'colors': 1585, 'bce': 1586, 'bt': 1587, 'rotating': 1588, 'shorter': 1589, 'fraccmin': 1590, 'image': 1591, 'dark': 1592, 'slanted': 1593, 'xed': 1594, 'su': 1595, 'rearranging': 1596, 'item': 1597, 'contained': 1598, 'lowest': 1599, 'estimated': 1600, 'topleft': 1601, 'approximating': 1602, 'irrelevant': 1603, 'parllelogram': 1604, 'various': 1605, 'regions': 1606, 'lable': 1607, 'symbols': 1608, 'converting': 1609, 'og': 1610, 'act': 1611, 'recreated': 1612, 'recipes': 1613, 'baseheight': 1614, 'topwidthbaseheight': 1615, 'topbottomfb': 1616, 'already': 1617, 'partsthere': 1618, 'polyhedra': 1619, 'send': 1620, 'directions': 1621, 'dend': 1622, 'signial': 1623, 'labaled': 1624, 'shortage': 1625, 'newrecipe': 1626, 'willegible': 1627, 'sidethe': 1628, 'sidethere': 1629, 'qrst': 1630, 'continues': 1631, 'lengthheight': 1632, 'heightnumber': 1633, 'provide': 1634, 'gets': 1635, 'home': 1636, 'inequality': 1637, 'closed': 1638, 'said': 1639, 'obtuce': 1640, 'noth': 1641, 'range': 1642, 'panit': 1643, 'billegible': 1644, 'triangel': 1645, 'need': 1646, 'indented': 1647, 'object': 1648, 'forming': 1649, 'mak': 1650, 'corners': 1651, 'lebron': 1652, 'lastly': 1653, 'darcy': 1654, 'countedthe': 1655, 'tracing': 1656, 'cillegible': 1657, 'loona': 1658, 'labeledillegible': 1659, 'aarrow': 1660, 'hrs': 1661, 'decoposed': 1662, 'cop': 1663, 'columnhr': 1664, 'timesx': 1665, 'xwith': 1666, 'timesillegible': 1667, 'sids': 1668, 'sqaures': 1669, 'tast': 1670, 'saste': 1671, 'diff': 1672, 'pinapple': 1673, 'recipies': 1674, 'rat': 1675, 'came': 1676, 'dosent': 1677, 'reverse': 1678, 'strips': 1679, 'distribution': 1680, 'expand': 1681, 'xy': 1682, 'quantities': 1683, 'repeat': 1684, 'maritime': 1685, 'flag': 1686, 'decompasses': 1687, 'topside': 1688, 'tsov': 1689}\n"
     ]
    }
   ],
   "source": [
    "# for word, index in tokenizer.word_index.items():\n",
    "#     print(index, \". \", word)\n",
    "print(tokenizer.word_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
